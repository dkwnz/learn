{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('dataset.csv',header=None,sep=',')\n",
    "df = np.array(df)\n",
    "X = df[:,0:7]\n",
    "y = df[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# normalize the data attributes\n",
    "normalized_X = preprocessing.normalize(X)\n",
    "# standardize the data attributes\n",
    "standardized_X = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.12390788  0.27757572  0.11867507  0.09980847  0.08708251  0.1546408\n",
      "  0.13830955]\n"
     ]
    }
   ],
   "source": [
    "#特征选择\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X, y)\n",
    "# display the relative importance of each attribute\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False False False False  True  True]\n",
      "[1 2 3 5 4 1 1]\n"
     ]
    }
   ],
   "source": [
    "#特征工程\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "# create the RFE model and select 3 attributes\n",
    "rfe = RFE(model, 3)\n",
    "rfe = rfe.fit(X, y)\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.89      0.84       500\n",
      "        1.0       0.74      0.55      0.63       268\n",
      "\n",
      "avg / total       0.77      0.77      0.77       768\n",
      "\n",
      "[[447  53]\n",
      " [120 148]]\n"
     ]
    }
   ],
   "source": [
    "#逻辑回归\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = y\n",
    "predicted = model.predict(X)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.86      0.83       500\n",
      "        1.0       0.69      0.60      0.64       268\n",
      "\n",
      "avg / total       0.76      0.77      0.76       768\n",
      "\n",
      "[[429  71]\n",
      " [108 160]]\n"
     ]
    }
   ],
   "source": [
    "#朴素贝叶斯\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(X, y)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = y\n",
    "predicted = model.predict(X)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.88      0.85       500\n",
      "        1.0       0.75      0.65      0.70       268\n",
      "\n",
      "avg / total       0.80      0.80      0.80       768\n",
      "\n",
      "[[442  58]\n",
      " [ 93 175]]\n"
     ]
    }
   ],
   "source": [
    "#knn\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# fit a k-nearest neighbor model to the data\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X, y)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = y\n",
    "predicted = model.predict(X)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00       500\n",
      "        1.0       1.00      1.00      1.00       268\n",
      "\n",
      "avg / total       1.00      1.00      1.00       768\n",
      "\n",
      "[[500   0]\n",
      " [  0 268]]\n"
     ]
    }
   ],
   "source": [
    "#决策树\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# fit a CART model to the data\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X, y)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = y\n",
    "predicted = model.predict(X)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.66233766233766234"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#svm\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "# fit a SVM model to the data\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = y\n",
    "predicted = model.predict(X)\n",
    "# summarize the fit of the model\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#读取数据，以逗号隔开的csv文件\n",
    "dataset = pd.read_csv('dataset.csv', header=None, sep=',')\n",
    "dataset = np.array(dataset)\n",
    "X_len = len(dataset[0]) - 1\n",
    "X = dataset[:,:X_len]\n",
    "\n",
    "y = dataset[:,X_len:].reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((768, 8), (768,))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#交叉验证\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=7)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#数据分割\n",
    "from sklearn import cross_validation\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.82      0.87      0.85       500\n",
      "        1.0       0.74      0.65      0.69       268\n",
      "\n",
      "avg / total       0.79      0.80      0.79       768\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.79487179487179482"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练\n",
    "clf = KNeighborsClassifier().fit(X_train, y_train)\n",
    "expected = y\n",
    "predicted = clf.predict(X)\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "score = clf.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入训练数据文件dataset.csv\n"
     ]
    }
   ],
   "source": [
    "#选择文件\n",
    "filename = input('输入训练数据文件')\n",
    "dataset = pd.read_csv(filename, header=None, sep=',')\n",
    "dataset = np.array(dataset)\n",
    "X_len = len(dataset[0]) - 1\n",
    "X = dataset[:,:X_len]\n",
    "y = dataset[:,X_len:].reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#标准化\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率: 0.74025974026\n"
     ]
    }
   ],
   "source": [
    "clf_logreg = LogisticRegression()\n",
    "clf_nvby = GaussianNB()\n",
    "clf_knn = KNeighborsClassifier()\n",
    "clf_tree = DecisionTreeClassifier()\n",
    "clf_svm = SVC()\n",
    "clf = clf_tree\n",
    "clf.fit(X_train,y_train)\n",
    "#expected = y\n",
    "#predicted = clf.predict(X)\n",
    "#print(metrics.classification_report(expected, predicted))\n",
    "score = clf.score(X_test, y_test)\n",
    "print(r'准确率:',score)\n",
    "#print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入预测文件test.csv\n"
     ]
    }
   ],
   "source": [
    "testname = input('输入预测文件')\n",
    "preset = pd.read_csv(testname, header=None, sep=',')\n",
    "x = np.array(preset)\n",
    "predicted = clf.predict(x)\n",
    "x = pd.DataFrame(x)\n",
    "predicted = pd.DataFrame(predicted)\n",
    "res = pd.concat([x, predicted], axis=1)\n",
    "res.to_csv('res.csv',index=False,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BUTRP', 'OSRKI', 'PXZXU', 'DERHU']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import random\n",
    "\n",
    "def gencode(nums, lens):\n",
    "    pool = list(string.ascii_uppercase)\n",
    "    result = {}\n",
    "    while len(result)<nums:\n",
    "        key = ''\n",
    "        for i in range(lens):\n",
    "            key += random.choice(pool)\n",
    "        if key not in result:\n",
    "            result[key] = 1\n",
    "    return [key for key in result]\n",
    "print(gencode(4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFont, ImageDraw\n",
    "#import matplotlib as mpl\n",
    "#import matplotlib.pyplot as plt\n",
    "#import matplotlib.image as mpimg\n",
    "\n",
    "font = ImageFont.truetype('cambriaz.ttf', 54)\n",
    "img = Image.open(r'1.jpg')\n",
    "draw = ImageDraw.Draw(img)\n",
    "draw.text((img.size[0]*0.85, img.size[1]*0.05), u'5', font=font, fill=(255,0,0))\n",
    "img.save('2.jpg')\n",
    "#lena = mpimg.imread('2.jpg')\n",
    "#plt.imshow(lena)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mysql'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-52a192d2ff64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmysql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnector\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcode2sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmysql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mysql'"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "\n",
    "def code2sql():\n",
    "    db = mysql.connector.connect(user='',password='',host='',database='')\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"drop table if exists acode\")\n",
    "    cur.execute('create acode(id int primary key, code varchar(20))')\n",
    "    for key in gencode(4,5):\n",
    "        cur.execute(\"insert into acode(code) values('%s')\",key)\n",
    "    cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def countwd(filename):\n",
    "    txt = open(filename,'r').read().lower()\n",
    "    pat = r'[a-zA-Z-]+'\n",
    "    words = re.findall(pat,txt)\n",
    "    return(Counter(words).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def changephsize(oldir,weight,height,newdir):\n",
    "    photos = os.listdir(oldir)\n",
    "    for photo in photos:\n",
    "        phpath = os.path.join(oldir,photo)\n",
    "        if os.path.isfile(phpath):\n",
    "            im = Image.open(phpath)\n",
    "            newim = im.resize((weight,height))\n",
    "            newpath = os.path.join(newdir,photo)\n",
    "            newim.save(newpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 36)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def countcode(path):\n",
    "    common_lines = 0\n",
    "    code_lines = 0\n",
    "    for root, dirs,files in os.walk(path):\n",
    "        for file in files:\n",
    "            file_abs_path = os.path.join(root,file)\n",
    "            if os.path.splitext(file_abs_path)[1] == '.py':\n",
    "                with open(file_abs_path,'rb') as f:\n",
    "                    while True:\n",
    "                        line = f.readline().decode('utf-8')\n",
    "                        if not line:\n",
    "                            break\n",
    "                        elif line.strip().startswith('#'):\n",
    "                            common_lines += 1\n",
    "                        elif line.strip().startswith(\"'''\") or line.strip().startswith('\"\"\"'):\n",
    "                            common_lines += 1\n",
    "                            if line.count('\"\"\"') ==1 or line.count(\"'''\") ==1:\n",
    "                                while True:\n",
    "                                    line = fp.readline()\n",
    "                                    common_lines += 1\n",
    "                                    if (\"'''\" in line) or ('\"\"\"' in line):\n",
    "                                        break\n",
    "                        elif line.strip():\n",
    "                            code_lines += 1\n",
    "    return common_lines, code_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def partext(path):\n",
    "    text = []\n",
    "    url = []\n",
    "    with open(path,encoding='utf-8') as f:\n",
    "        html = BeautifulSoup(f, 'html.parser')\n",
    "        content = html.select('.content p')\n",
    "        for p in content:\n",
    "            text.append(p.text)\n",
    "        href = html.find_all('a')\n",
    "        for each in href:  \n",
    "            if str(each.get('href'))[:4]=='http':  \n",
    "                url.append(each.get('href'))\n",
    "        \n",
    "        return text,url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image,ImageFont,ImageDraw,ImageFilter\n",
    "import random\n",
    " \n",
    " \n",
    "#返回随机字母\n",
    "def charRandom():\n",
    "    return chr((random.randint(65,90)))\n",
    " \n",
    "#返回随机数字\n",
    "def numRandom():\n",
    "    return random.randint(0,9)\n",
    " \n",
    "#随机颜色\n",
    "def colorRandom1():\n",
    "    return (random.randint(64,255),random.randint(64,255),random.randint(64,255))\n",
    " \n",
    "#随机长生颜色2\n",
    "def colorRandom2():\n",
    "    return (random.randint(32,127),random.randint(32,127),random.randint(32,127))\n",
    " \n",
    "width = 60 * 4\n",
    "height = 60\n",
    "image = Image.new('RGB', (width,height), (255,255,255));\n",
    "#创建font对象\n",
    "font = ImageFont.truetype('cambriaz.ttf',36);\n",
    " \n",
    "#创建draw对象\n",
    "draw = ImageDraw.Draw(image)\n",
    "#填充每一个颜色\n",
    "for x in range(width):\n",
    "    for y in range(height):\n",
    "        draw.point((x,y), fill=colorRandom1())\n",
    "         \n",
    "#输出文字\n",
    "for t in range(4):\n",
    "    draw.text((60*t+10,10), charRandom(),font=font, fill=colorRandom2())\n",
    " #模糊\n",
    "image = image.filter(ImageFilter.BLUR)\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter your words: love\n",
      "Freedom\n"
     ]
    }
   ],
   "source": [
    "def filterwords():\n",
    "    words = set('')\n",
    "    f = open('filtered_words.txt', 'rb')\n",
    "    for l in f.readlines():\n",
    "        words.add(l.strip().decode('utf-8'))\n",
    "    f.close()\n",
    "    w = input('enter your words: ')\n",
    "    if w in words:\n",
    "        print('Freedom')\n",
    "    else:\n",
    "        print('Human Rights')\n",
    "filterwords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter your words: 我love北京\n",
      "我love***\n"
     ]
    }
   ],
   "source": [
    "def filterwords(iw):\n",
    "    words =[]\n",
    "    file = open('filtered_words.txt', 'rb')\n",
    "    for f in file.readlines():\n",
    "        words.append(f.decode('utf-8'))\n",
    "    file.close()\n",
    "    for i in range(len(words)):\n",
    "        word = words[i].strip()\n",
    "        if iw.find(word) > -1:\n",
    "            return word\n",
    "    return ''\n",
    "\n",
    "\n",
    "iw = input('enter your words: ')\n",
    "word = filterwords(iw)\n",
    "if word != '':\n",
    "    print(iw.replace(word, '***'))\n",
    "else:\n",
    "    print(iw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我love北京\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'我****'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replaced():\n",
    "    w = input()\n",
    "    words = []\n",
    "    file = open('filtered_words.txt', 'rb')\n",
    "    for line in file.readlines():\n",
    "        words.append(line.strip().decode('utf-8'))\n",
    "    file.close()\n",
    "    for word in words:\n",
    "        if word in w:\n",
    "            w = w.replace(word, '**')\n",
    "    return w\n",
    "replaced()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def down():\n",
    "    url =\"http://tieba.baidu.com/p/2166231880\"\n",
    "    save_path = 'pic'\n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.text,'html.parser')\n",
    "    picl = soup.select('.BDE_Image')\n",
    "    counter = 1\n",
    "    for pl in picl:\n",
    "        urlp = pl.get('src')\n",
    "        pic = requests.get(urlp).content\n",
    "        postfix = urlp[urlp.rfind('.'):]\n",
    "        file = open(r'pic/'+save_path+str(counter)+postfix,'wb')\n",
    "        try:\n",
    "            file.write(pic)\n",
    "        finally:\n",
    "            file.close()\n",
    "        counter += 1\n",
    "    print('下载了：%d张'%counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
